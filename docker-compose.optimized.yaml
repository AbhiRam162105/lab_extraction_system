# =============================================================================
# Lab Report Extraction System - Optimized Docker Compose
# =============================================================================
# Production-ready configuration with multiple workers and resource limits
#
# Usage:
#   docker-compose -f docker-compose.optimized.yaml up --build
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # Redis - Message Queue with LRU Eviction
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    command: >
      redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # PostgreSQL - Production Database
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: lab_extraction
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD:-labextract2024}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres -d lab_extraction" ]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Backend API Server
  # ---------------------------------------------------------------------------
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "6000:6000"
    environment:
      - GEMINI__API_KEY=${GEMINI__API_KEY}
      - GEMINI__MODEL=${GEMINI__MODEL:-gemini-2.5-flash-lite}
      - GEMINI__RATE_LIMIT=${GEMINI__RATE_LIMIT:-15}
      - REDIS__URL=redis://redis:6379/0
      - DATABASE__URL=postgresql://postgres:${DB_PASSWORD:-labextract2024}@postgres:5432/lab_extraction
      - PROCESSING__BATCH_SIZE=${PROCESSING__BATCH_SIZE:-15}
      - PROCESSING__ENABLE_CACHING=true
    volumes:
      - ./storage:/app/storage
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:6000/docs" ]
      interval: 30s
      timeout: 10s
      start_period: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Worker 1 - Normal Priority Queue
  # ---------------------------------------------------------------------------
  worker1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    command: rq worker lab_reports --url redis://redis:6379/0
    environment:
      - GEMINI__API_KEY=${GEMINI__API_KEY}
      - GEMINI__MODEL=${GEMINI__MODEL:-gemini-2.5-flash-lite}
      - GEMINI__RATE_LIMIT=${GEMINI__RATE_LIMIT:-15}
      - REDIS__URL=redis://redis:6379/0
      - DATABASE__URL=postgresql://postgres:${DB_PASSWORD:-labextract2024}@postgres:5432/lab_extraction
      - PROCESSING__ENABLE_CACHING=true
      - OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
    volumes:
      - ./storage:/app/storage
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      backend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "python", "-c", "import redis; redis.from_url('redis://redis:6379/0').ping()" ]
      interval: 30s
      timeout: 10s
      start_period: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Worker 2 - Batch Queue
  # ---------------------------------------------------------------------------
  worker2:
    build:
      context: .
      dockerfile: Dockerfile.worker
    command: rq worker batch --url redis://redis:6379/0
    environment:
      - GEMINI__API_KEY=${GEMINI__API_KEY}
      - GEMINI__MODEL=${GEMINI__MODEL:-gemini-2.5-flash-lite}
      - GEMINI__RATE_LIMIT=${GEMINI__RATE_LIMIT:-15}
      - REDIS__URL=redis://redis:6379/0
      - DATABASE__URL=postgresql://postgres:${DB_PASSWORD:-labextract2024}@postgres:5432/lab_extraction
      - PROCESSING__ENABLE_CACHING=true
      - OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
    volumes:
      - ./storage:/app/storage
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      backend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "python", "-c", "import redis; redis.from_url('redis://redis:6379/0').ping()" ]
      interval: 30s
      timeout: 10s
      start_period: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Worker 3 - High Priority Queue
  # ---------------------------------------------------------------------------
  worker3:
    build:
      context: .
      dockerfile: Dockerfile.worker
    command: rq worker high_priority --url redis://redis:6379/0
    environment:
      - GEMINI__API_KEY=${GEMINI__API_KEY}
      - GEMINI__MODEL=${GEMINI__MODEL:-gemini-2.5-flash-lite}
      - GEMINI__RATE_LIMIT=${GEMINI__RATE_LIMIT:-15}
      - REDIS__URL=redis://redis:6379/0
      - DATABASE__URL=postgresql://postgres:${DB_PASSWORD:-labextract2024}@postgres:5432/lab_extraction
      - PROCESSING__ENABLE_CACHING=true
      - OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
    volumes:
      - ./storage:/app/storage
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      backend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "python", "-c", "import redis; redis.from_url('redis://redis:6379/0').ping()" ]
      interval: 30s
      timeout: 10s
      start_period: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Frontend - Streamlit UI
  # ---------------------------------------------------------------------------
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://backend:6000/api/v1
    volumes:
      - ./storage:/app/storage
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8501" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:


networks:
  default:
    name: lab_extraction_network
